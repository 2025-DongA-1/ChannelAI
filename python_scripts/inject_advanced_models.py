import nbformat as nbf
try:
    with open('ai_experiments.ipynb', 'r', encoding='utf-8') as f:
        nb = nbf.read(f, as_version=4)

    text_xg = "## 4. XGBoost ê¸°ë°˜ ì•± ì„¤ì¹˜(ì „í™˜) ì˜ˆì¸¡ ëª¨ë¸\në¹„ìš©, ë…¸ì¶œ, í´ë¦­ ì •ë³´ ë° ë§¤ì²´ ì •ë³´ë¥¼ ì…ë ¥í•˜ë©´ ë°œìƒí•  **ì„¤ì¹˜ ìˆ˜**ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê³ ê¸‰ ëª¨ë¸ì…ë‹ˆë‹¤."
    code_xg = """\
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import mean_absolute_error
import warnings
warnings.filterwarnings('ignore')

# ê²°ì¸¡ì¹˜ë¥¼ 0ìœ¼ë¡œ ì±„ì›€
df_ml = raw_df.fillna(0).copy()

# ìš”ì¼ ë° ë§¤ì²´ ì¢…ë¥˜ë¥¼ ê¸°ê³„ê°€ ì¸ì‹í•  ìˆ˜ ìˆëŠ” ìˆ«ìë¡œ ë³€í™˜ (Label Encoding)
le_day = LabelEncoder()
df_ml['ìš”ì¼_encoded'] = le_day.fit_transform(df_ml['ìš”ì¼'].astype(str))

le_platform = LabelEncoder()
df_ml['platform_encoded'] = le_platform.fit_transform(df_ml['ë§¤ì²´'].astype(str))

# [ëª¨ë¸ í•™ìŠµ] 
features = ['platform_encoded', 'ìš”ì¼_encoded', 'ë…¸ì¶œ', 'ë¹„ìš©', 'í´ë¦­']
target = 'ì„¤ì¹˜' 

X = df_ml[features]
y_reg = df_ml[target]

# ë°ì´í„°ë¥¼ í•™ìŠµìš© 80%, í…ŒìŠ¤íŠ¸ìš© 20%ë¡œ ë‚˜ëˆ”
X_train, X_test, y_train, y_test = train_test_split(X, y_reg, test_size=0.2, random_state=42)

# ë°ì´í„° ìŠ¤ì¼€ì¼ë§ (ê°’ì˜ ë²”ìœ„ í‘œì¤€í™”)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# XGBoost íšŒê·€ ëª¨ë¸ (Regressor)
xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)
xgb_model.fit(X_train_scaled, y_train)

# ì •í™•ë„ í‰ê°€
y_pred = xgb_model.predict(X_test_scaled)
mae = mean_absolute_error(y_test, y_pred)
print(f"âœ… XGBoost ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
print(f"ğŸ“Š í‰ê·  ì˜¤ì°¨(MAE): ì•½ {mae:.2f} ê±´")

# ìƒ˜í”Œ ë°ì´í„°ì— ëŒ€í•œ AI ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸
if len(X_test) > 0:
    sample_idx = 0
    sample_features = X_test.iloc[sample_idx]
    platform_name = le_platform.inverse_transform([int(sample_features['platform_encoded'])])[0]

    print(f"\\n[ğŸ’¡ ìƒ˜í”Œ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜]")
    print(f"ì…ë ¥: ë§¤ì²´= {platform_name}, ì§€ì¶œ ë¹„ìš©= {sample_features['ë¹„ìš©']:,.0f}ì›, ë…¸ì¶œ= {sample_features['ë…¸ì¶œ']:,.0f}íšŒ, í´ë¦­= {sample_features['í´ë¦­']:.0f}íšŒ")
    print(f"ğŸ‘‰ ì˜ˆì¸¡ ì„¤ì¹˜ ìˆ˜: {y_pred[sample_idx]:.1f} ê°œ (ì‹¤ì œ ë°ì´í„°: {y_test.iloc[sample_idx]:.0f} ê°œ)")
"""

    text_rf = "## 5. Random Forest ê¸°ë°˜ ìµœê³  íš¨ìœ¨ ë§¤ì²´ ì¶”ì²œ ëª¨ë¸\nì—¬ëŸ¬ ë§¤ì²´ ì¤‘ ë™ì¼í•œ ì¡°ê±´(ì¼ì¼ ì´ ì˜ˆì‚°, ì´ ë…¸ì¶œìˆ˜ ë“±)ì´ ì£¼ì–´ì¡Œì„ ë•Œ **ì–´ë–¤ ë§¤ì²´ê°€ ê°€ì¥ ì„±ê³¼(ë¹„ìš© ëŒ€ë¹„ ì„¤ì¹˜ìˆ˜)ê°€ ì¢‹ì„ì§€ 1ìˆœìœ„ë¥¼ ì¶”ì²œ**í•©ë‹ˆë‹¤."
    
    code_rf = """\
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# 1. ì¼ìë³„ë¡œ íš¨ìœ¨(ë¹„ìš© ëŒ€ë¹„ ì„¤ì¹˜ ìˆ˜)ì´ ê°€ì¥ ì¢‹ì•˜ë˜ 1ë“± ë§¤ì²´ ë„ì¶œ
df_ml['íš¨ìœ¨ì ìˆ˜'] = df_ml['ì„¤ì¹˜'] / (df_ml['ë¹„ìš©'] + 1) # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒ ë°©ì§€
best_idx = df_ml.groupby('ë‚ ì§œ')['íš¨ìœ¨ì ìˆ˜'].idxmax()
best_daily_df = df_ml.loc[best_idx]

# 2. í•´ë‹¹ ë‚ ì§œ ì „ì²´ì˜ ê´‘ê³  í™˜ê²½ ìš”ì•½(ì´ ë…¸ì¶œ, ì´ ë¹„ìš©, ì´ í´ë¦­)
daily_agg = df_ml.groupby('ë‚ ì§œ').agg({
    'ë…¸ì¶œ': 'sum',
    'ë¹„ìš©': 'sum',
    'í´ë¦­': 'sum'
}).reset_index()

best_daily_df = best_daily_df[['ë‚ ì§œ', 'ë§¤ì²´']].rename(columns={'ë§¤ì²´': 'best_platform'})
rf_data = pd.merge(daily_agg, best_daily_df, on='ë‚ ì§œ')

if len(rf_data) > 5: # í•™ìŠµì„ í•˜ë ¤ë©´ ìµœì†Œí•œì˜ ì¼ì ë°ì´í„°ê°€ í•„ìš”í•¨
    X_rf = rf_data[['ë…¸ì¶œ', 'ë¹„ìš©', 'í´ë¦­']]
    y_rf = rf_data['best_platform']
    
    X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, test_size=0.2, random_state=42)
    
    # 3. Random Forest ë¶„ë¥˜ ëª¨ë¸ (Classifier)
    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
    rf_model.fit(X_train_rf, y_train_rf)
    
    # ì •í™•ë„ í‰ê°€
    y_pred_rf = rf_model.predict(X_test_rf)
    acc = accuracy_score(y_test_rf, y_pred_rf)
    
    print(f"âœ… Random Forest ë§¤ì²´ ì¶”ì²œ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    print(f"ğŸ“Š ëª¨ë¸ ì •í™•ë„: {acc:.2f}")
    
    if len(X_test_rf) > 0:
        sample_rf_idx = 0
        test_case = X_test_rf.iloc[sample_rf_idx].to_frame().T
        pred_best = rf_model.predict(test_case)[0]
        actual_best = y_test_rf.iloc[sample_rf_idx]
        
        print(f"\\n[ğŸ’¡ ìµœì  ë§¤ì²´ ì¶”ì²œ ì‹œë®¬ë ˆì´ì…˜]")
        print(f"ì…ë ¥: ì˜¤ëŠ˜ì˜ ì˜ˆìƒ ì´ ë…¸ì¶œ ìˆ˜ '{test_case['ë…¸ì¶œ'].iloc[0]:,.0f}íšŒ', ì´ ê´‘ê³  ì˜ˆì‚° '{test_case['ë¹„ìš©'].iloc[0]:,.0f}ì›'")
        print(f"ğŸ‘‰ AI ì¶”ì²œ ì§‘ì¤‘ ë§¤ì²´: **{pred_best}**")
        print(f"   (ì°¸ê³ : ì‹¤ì œ ê³¼ê±° ë°ì´í„°ì—ì„œ ìœ„ì˜ ìƒí™©ì¼ ë•Œ ê°€ì¥ íš¨ìœ¨ ë†’ì•˜ë˜ ë§¤ì²´ëŠ” '{actual_best}')")
else:
    print("ê°€ì ¸ì˜¨ CSV ë°ì´í„°ì˜ ì¼ì ìˆ˜ê°€ í•™ìŠµì„ í•˜ê¸°ì—ëŠ” ì¡°ê¸ˆ ë¶€ì¡±í•©ë‹ˆë‹¤. ë°ì´í„°ê°€ ë” ëˆ„ì ë˜ë©´ ì •í™•í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
    display(rf_data)
"""

    nb.cells.extend([
        nbf.v4.new_markdown_cell(text_xg),
        nbf.v4.new_code_cell(code_xg),
        nbf.v4.new_markdown_cell(text_rf),
        nbf.v4.new_code_cell(code_rf)
    ])

    with open('ai_experiments.ipynb', 'w', encoding='utf-8') as f:
        nbf.write(nb, f)
        
    print("SUCCESS")
except Exception as e:
    print(e)
