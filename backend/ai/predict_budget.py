import sys
import json
import pandas as pd
import numpy as np
import xgboost as xgb
from scipy.optimize import linprog
import os
from datetime import datetime

# ==========================================
# â˜… [ì—¬ê¸°ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”] ìœˆë„ìš° ì´ëª¨ì§€ ì—ëŸ¬ ë°©ì§€ ì½”ë“œ
# ==========================================
if sys.platform.startswith('win'):
    sys.stdout.reconfigure(encoding='utf-8')
# ==========================================

# ==========================================
# â˜… [NEW] stderr ë¡œê¹… (stdout JSON ê¹¨ì§ ë°©ì§€)
# ==========================================
def log(*args):
    print(*args, file=sys.stderr)

# ==========================================
# 1. Numpy ìˆ«ì ë³€í™˜ê¸° (ì—ëŸ¬ ë°©ì§€ìš©)
# ==========================================
class NumpyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        if isinstance(obj, np.floating) or isinstance(obj, float):
            return float(round(obj, 2))
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        return super(NumpyEncoder, self).default(obj)

# ==========================================
# â˜… [NEW] ê³¼ê±° ë°ì´í„° ìƒì„± í•¨ìˆ˜ (7ì¼/30ì¼ ëŒ€ì‘)
# ==========================================
def generate_past_history(predicted_roas, duration=7):
    history = []

    # ê³¼ê±° (duration-1)ì¼ë¶€í„° 1ì¼ ì „ê¹Œì§€ ë°˜ë³µ
    for i in range(duration - 1, 0, -1):
        day_label = f"{i}ì¼ ì „"

        # íŠ¸ë Œë“œ ì‹œë®¬ë ˆì´ì…˜
        trend_factor = 1.0 - (i * 0.015)
        if trend_factor < 0.6:
            trend_factor = 0.6

        row = {"day": day_label}

        # predicted_roas ìˆœì„œ: [Naver, Meta, Google, Karrot]
        row["Naver"] = round(float(predicted_roas[0] * trend_factor * np.random.uniform(0.9, 1.1)), 2)
        row["Meta"] = round(float(predicted_roas[1] * trend_factor * np.random.uniform(0.9, 1.1)), 2)
        row["Google"] = round(float(predicted_roas[2] * trend_factor * np.random.uniform(0.9, 1.1)), 2)
        row["Karrot"] = round(float(predicted_roas[3] * trend_factor * np.random.uniform(0.9, 1.1)), 2)

        history.append(row)

    # ë§ˆì§€ë§‰ìœ¼ë¡œ 'ì˜¤ëŠ˜(ì˜ˆì¸¡)' ë°ì´í„° ì¶”ê°€
    history.append({
        "day": "ì˜¤ëŠ˜(ì˜ˆì¸¡)",
        "Naver": round(float(predicted_roas[0]), 2),
        "Meta": round(float(predicted_roas[1]), 2),
        "Google": round(float(predicted_roas[2]), 2),
        "Karrot": round(float(predicted_roas[3]), 2)
    })

    # âœ… [FIX] day ë¼ë²¨ì— ì„ì¼ ìˆ˜ ìˆëŠ” ê³µë°±/ì¤„ë°”ê¿ˆ ìµœì¢… ì •ë¦¬(ë°©íƒ„)
    for r in history:
        if "day" in r and isinstance(r["day"], str):
            r["day"] = r["day"].replace("\n", "").replace("\r", "").strip()

    return history

# ==========================================
# â˜… [NEW] ì˜ˆì¸¡ ROAS í´ë¦¬í•‘ (ë¹„í˜„ì‹¤ íŠ ë°©ì§€)
# ==========================================
def clip_predicted_roas(pred, min_roas=50.0, max_roas=800.0):
    pred = np.asarray(pred, dtype=float)
    return np.clip(pred, min_roas, max_roas)

# ==========================================
# â˜… [NEW] ìµœì í™” boundsë¥¼ ì´ì˜ˆì‚°ì— ë§ê²Œ ì•ˆì „í•˜ê²Œ ë§Œë“œëŠ” í•¨ìˆ˜
# ==========================================
def build_safe_bounds(n, total_budget, min_budget_default=30000, max_ratio_default=0.6):
    """
    - ì´ì˜ˆì‚°ì´ ì‘ì•„ì„œ (n * 30000) ì¶©ì¡± ëª»í•˜ë©´ ìë™ìœ¼ë¡œ minì„ ë‚®ì¶¤
    - maxë„ total_budget*0.6ì´ minë³´ë‹¤ ì‘ì•„ì§€ì§€ ì•Šê²Œ ë³´ì •
    """
    total_budget = float(total_budget)

    if n <= 0:
        return []

    # ì±„ë„ë‹¹ ìµœì†Œ ì˜ˆì‚° (ì´ì˜ˆì‚°ì´ ì‘ìœ¼ë©´ ìë™ìœ¼ë¡œ ë‚®ì¶˜ë‹¤)
    min_per = float(min_budget_default)
    if total_budget < n * min_per:
        min_per = 0.0

    # ì±„ë„ë‹¹ ìµœëŒ€ ì˜ˆì‚°
    max_per = float(total_budget * max_ratio_default)

    # maxê°€ minë³´ë‹¤ ì‘ìœ¼ë©´(ì´ì˜ˆì‚° ë§¤ìš° ì‘ìŒ) maxë„ minìœ¼ë¡œ ë§ì¶¤
    if max_per < min_per:
        max_per = min_per

    # í•œ ë²ˆ ë” ë°©ì–´
    if total_budget - (n * min_per) < -1e-6:
        min_per = 0.0
        if max_per < min_per:
            max_per = min_per

    return [(min_per, max_per) for _ in range(n)]

# ==========================================
# â˜… [NEW] PRO ë¦¬í¬íŠ¸ ìƒì„± í•¨ìˆ˜ (ì»¨ì„¤íŒ… í”„ë ˆì„ì›Œí¬)
# ==========================================
def build_pro_report(
    total_budget,
    allocated_budget,
    predicted_roas,
    expected_revenue,
    duration,
    clip_min=50.0,
    clip_max=800.0,
    min_budget_default=30000,
    max_ratio_default=0.6
):
    """
    ë¦¬í¬íŠ¸ êµ¬ì„±:
    ğŸ“¢ Executive Summary
    ğŸ” ë§¤ì²´ë³„ ì •ë°€ ì§„ë‹¨ (í˜„ìƒ â†’ ë°ì´í„° ê·¼ê±° â†’ ì „ëµ â†’ ê¸°ëŒ€íš¨ê³¼)
    âœ… ì‹¤í–‰ ê°€ì´ë“œ (ì•¡ì…˜ ì•„ì´í…œ)
    âš ï¸ í•œê³„/ë©´ì±…
    """
    # ìˆœì„œ ê³ ì •: [Naver, Meta, Google, Karrot]
    channel_codes = ["naver", "meta", "google", "karrot"]
    channel_names = ["ë„¤ì´ë²„", "ë©”íƒ€", "êµ¬ê¸€", "ë‹¹ê·¼"]
    channel_names_kr = {
        "ë„¤ì´ë²„": "ë„¤ì´ë²„",
        "ë©”íƒ€": "ì¸ìŠ¤íƒ€ê·¸ë¨/í˜ì´ìŠ¤ë¶",
        "êµ¬ê¸€": "êµ¬ê¸€/ìœ íŠœë¸Œ",
        "ë‹¹ê·¼": "ë‹¹ê·¼ë§ˆì¼“"
    }
    channel_display = [channel_names_kr.get(n, n) for n in channel_names]

    total_budget = float(total_budget)
    alloc = np.asarray(allocated_budget, dtype=float)
    roas = np.asarray(predicted_roas, dtype=float)

    # ì±„ë„ë³„ ê¸°ëŒ€ ë§¤ì¶œ(ì¶”ì •): ì˜ˆì‚° * (ROAS/100)
    exp_rev_by_channel = alloc * (roas / 100.0)

    # í•µì‹¬ ì§€í‘œ
    best_idx = int(np.argmax(roas))
    best_name = channel_display[best_idx]
    best_roas = float(roas[best_idx])
    best_alloc = float(alloc[best_idx])
    best_ratio = int(round((best_alloc / total_budget) * 100)) if total_budget > 0 else 0

    # 2ë“± ëŒ€ë¹„ ìš°ìœ„
    sorted_idx = np.argsort(-roas)
    top1 = sorted_idx[0]
    top2 = sorted_idx[1] if len(sorted_idx) > 1 else top1
    gap_vs_2nd = float(roas[top1] - roas[top2])

    # ì œì•½ì¡°ê±´ ìš”ì•½
    # (í˜„ ì½”ë“œì˜ bounds ë£°ì„ ì‚¬ëŒì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ)
    min_per = min_budget_default
    if total_budget < len(roas) * min_per:
        min_per = 0
    max_per = int(total_budget * max_ratio_default)

    # ì±„ë„ë³„ â€œì§„ë‹¨ ë¬¸ì¥â€ ë§Œë“¤ê¸°
    lines = []
    lines.append(f"ğŸ“¢ Executive Summary: **{best_name}** ì¤‘ì‹¬ìœ¼ë¡œ ì˜ˆì‚°ì„ ì¬ë°°ì¹˜í•´ **ì˜ˆìƒ ë§¤ì¶œì„ ê·¹ëŒ€í™”**í•˜ëŠ” ì „ëµì´ ìµœì ì…ë‹ˆë‹¤. (Top2 ëŒ€ë¹„ ROAS ì°¨ì´: **{gap_vs_2nd:.1f}%p**)")

    lines.append("")
    lines.append("ğŸ” ë§¤ì²´ë³„ ì •ë°€ ì§„ë‹¨ (í˜„ìƒ â†’ ë°ì´í„° ê·¼ê±° â†’ ì „ëµ â†’ ê¸°ëŒ€íš¨ê³¼)")

    # ë¹„êµ/ê·¼ê±°ìš©: í‰ê·  ROAS
    avg_roas = float(np.mean(roas)) if len(roas) else 0.0

    for i in range(len(roas)):
        name = channel_display[i]
        r = float(roas[i])
        b = float(alloc[i])
        ratio = int(round((b / total_budget) * 100)) if total_budget > 0 else 0
        rev = float(exp_rev_by_channel[i])

        # ìƒëŒ€ ë¹„êµ
        vs_avg = r - avg_roas
        compare_word = "ìƒíšŒ" if vs_avg >= 0 else "í•˜íšŒ"
        compare_abs = abs(vs_avg)

        # ì „ëµ í†¤: ì˜ˆì‚° ë¹„ì¤‘ì— ë”°ë¼ ì¶”ì²œ ì•¡ì…˜ì„ ë‹¤ë¥´ê²Œ
        if i == best_idx:
            action = f"**ì§‘ì¤‘ íˆ¬ì ìœ ì§€**(ìƒí•œ {int(max_ratio_default*100)}% ë²”ìœ„ ë‚´) + ê³ íš¨ìœ¨ êµ¬ê°„ í™•ì¥"
            effect = f"ë™ì¼ ì˜ˆì‚° ëŒ€ë¹„ **ì˜ˆìƒ ë§¤ì¶œ ê¸°ì—¬**ê°€ ê°€ì¥ í¼(ì¶”ì • {int(round(rev)):,}ì›)."
        else:
            if ratio <= 10:
                action = "**í…ŒìŠ¤íŠ¸ ì˜ˆì‚° ìœ ì§€**(ì†Œì•¡) + ì†Œì¬/íƒ€ê²Ÿ ê°œì„  í›„ ì¬í‰ê°€"
                effect = "ë‚­ë¹„ ë¦¬ìŠ¤í¬ë¥¼ ì¤„ì´ë©´ì„œ ê°œì„  ì—¬ì§€ë¥¼ íƒìƒ‰."
            elif ratio <= 30:
                action = "**ê· í˜• ìš´ì˜** + ROAS í•˜ë½ ì‹œ ìë™ ê°ì•¡ ê¸°ì¤€ ì„¤ì •"
                effect = "ì„±ê³¼ ë³€ë™ì— ëŒ€ì‘í•˜ë©° ì•ˆì •ì ìœ¼ë¡œ ìš´ì˜."
            else:
                action = "**ë¶€ë¶„ ê°ì•¡ ê³ ë ¤** + ê³ íš¨ìœ¨ ì±„ë„ë¡œ ì¼ë¶€ ì´ë™"
                effect = "ì˜ˆìƒ ìˆ˜ìµë¥ ì„ ëŒì–´ì˜¬ë¦¬ëŠ” ë°©í–¥ìœ¼ë¡œ ì¬ë°°ë¶„."

        # ë°ì´í„° ê·¼ê±°(ìˆ«ì ì¤‘ì‹¬)
        lines.append(
            f"â€¢ **{name}**\n"
            f"  - í˜„ìƒ: ì˜ˆì¸¡ ROAS **{r:.2f}%** / ì˜ˆì‚° ë°°ì • **{ratio}%**\n"
            f"  - ë°ì´í„° ê·¼ê±°: í‰ê·  ëŒ€ë¹„ **{compare_abs:.2f}%p {compare_word}**, ì˜ˆìƒ ë§¤ì¶œ ê¸°ì—¬ **{int(round(rev)):,}ì›**\n"
            f"  - ì „ëµ ì œì•ˆ: {action}\n"
            f"  - ê¸°ëŒ€ íš¨ê³¼: {effect}"
        )

    lines.append("")
    lines.append("âœ… ìˆ˜ìµ ê·¹ëŒ€í™”ë¥¼ ìœ„í•œ ì‹¤ì²œ ê°€ì´ë“œ (ë°”ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜)")
    lines.append(f"â€¢ **ì˜ˆì‚° ì§‘í–‰(ì˜¤ëŠ˜~{duration}ì¼)**: {best_name}ì— **{best_ratio}%** ìˆ˜ì¤€ìœ¼ë¡œ ì§‘ì¤‘ ìš´ì˜í•˜ê³ , ë‚˜ë¨¸ì§€ëŠ” í…ŒìŠ¤íŠ¸/ë°©ì–´ ì˜ˆì‚°ìœ¼ë¡œ ìœ ì§€í•˜ì„¸ìš”.")
    lines.append("â€¢ **ìš´ì˜ ë£°(ê°„ë‹¨ ìë™í™”)**: 7ì¼ ê¸°ì¤€ ROASê°€ í‰ê·  ëŒ€ë¹„ í•˜íšŒí•˜ëŠ” ì±„ë„ì€ **ì†Œì¬/íƒ€ê²Ÿ 1íšŒ ê°œì„  í›„** ê°œì„  ì—†ìœ¼ë©´ ê°ì•¡í•˜ëŠ” ë£°ì„ ì ìš©í•˜ì„¸ìš”.")
    lines.append("â€¢ **ê²€ì¦ ë°©ë²•(ë‚­ë¹„ ë°©ì§€)**: ì±„ë„ë³„ë¡œ 'í´ë¦­â†’ì „í™˜â†’ë§¤ì¶œ' ì´ë²¤íŠ¸ê°€ ì •ìƒ ìˆ˜ì§‘ë˜ëŠ”ì§€ ë¨¼ì € ì ê²€í•˜ê³ , ë°ì´í„°ê°€ ë¶ˆì™„ì „í•˜ë©´ ë³´ìˆ˜ì ìœ¼ë¡œ ìš´ì˜í•˜ì„¸ìš”.")

    lines.append("")
    lines.append("ğŸ“Œ ì•Œê³ ë¦¬ì¦˜/ì œì•½ì¡°ê±´ ê·¼ê±° (íˆ¬ëª…ì„±)")
    lines.append(f"â€¢ ë³¸ ë°°ë¶„ì€ **ì´ì˜ˆì‚° {int(total_budget):,}ì›** ë‚´ì—ì„œ ê¸°ëŒ€ ìˆ˜ìµ(ì˜ˆì‚°Ã—ì˜ˆì¸¡ROAS)ì„ ìµœëŒ€í™”í•˜ë„ë¡ ê³„ì‚°ë˜ì—ˆìŠµë‹ˆë‹¤.")
    lines.append(f"â€¢ ì±„ë„ë³„ ì˜ˆì‚°ì€ ìµœì†Œ **{int(min_per):,}ì›**(ì´ì˜ˆì‚°ì´ ì‘ìœ¼ë©´ 0ì›) ~ ìµœëŒ€ **{int(max_per):,}ì›**(ì´ì˜ˆì‚°ì˜ {int(max_ratio_default*100)}%) ë²”ìœ„ ì œì•½ì„ ì ìš©í–ˆìŠµë‹ˆë‹¤.")
    lines.append(f"â€¢ ì˜ˆì¸¡ ROASëŠ” ì´ìƒì¹˜ ë°©ì§€ë¥¼ ìœ„í•´ **{int(clip_min)}% ~ {int(clip_max)}%** ë²”ìœ„ë¡œ í´ë¦¬í•‘ë˜ì—ˆìŠµë‹ˆë‹¤.")

    

    # í”„ë¡ íŠ¸ íŒŒì‹±ì„ ìœ„í•´ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ì¡° ìœ ì§€
    return "\n".join(lines)

# ==========================================
# 2. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ==========================================
def main():
    try:
        # [ë°ì´í„° ìˆ˜ì‹ ]
        if len(sys.argv) < 2:
            # í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ê¸°ë³¸ê°’)
            data = {
                "total_budget": 500000,
                "duration": 7,
                "features": [
                    {"ì±„ë„ëª…_Naver": 1, "ë¹„ìš©": 100000, "ROAS": 300, "trend_score": 90},
                    {"ì±„ë„ëª…_Meta": 1, "ë¹„ìš©": 100000, "ROAS": 200, "trend_score": 90},
                    {"ì±„ë„ëª…_Google": 1, "ë¹„ìš©": 100000, "ROAS": 250, "trend_score": 90},
                    {"ì±„ë„ëª…_Karrot": 1, "ë¹„ìš©": 50000, "ROAS": 150, "trend_score": 90}
                ]
            }
        else:
            # ì‹¤ì „ ëª¨ë“œ (Node.jsì—ì„œ ë°›ìŒ)
            input_data = sys.argv[1]
            data = json.loads(input_data)

    except Exception as e:
        log(json.dumps({"error": f"ë°ì´í„° ìˆ˜ì‹  ì‹¤íŒ¨: {str(e)}"}, ensure_ascii=False))
        sys.exit(1)

    # [ìˆ˜ì •] ë³€ìˆ˜ ì¶”ì¶œ (ë¦¬ìŠ¤íŠ¸/ê°ì²´ ëª¨ë‘ ëŒ€ì‘í•˜ëŠ” ì•ˆì „í•œ ì½”ë“œ)
    if isinstance(data, list):
        features_list = data
        total_budget = 500000
        duration = 7
    else:
        features_list = data.get('features', [])
        total_budget = data.get('total_budget', 500000)
        duration = data.get('duration', 7)

    # ==========================================
    # [ì¤‘ìš”] train_model_v2.pyì™€ ì»¬ëŸ¼(í”¼ì²˜) ì •í•© ë§ì¶”ê¸°
    # - í•™ìŠµì—ì„œëŠ” channel_* ì‚¬ìš©
    # - predictì—ì„œë„ ìµœì¢…ì ìœ¼ë¡œ channel_*ë¡œ ë§ì¶˜ë‹¤
    # ==========================================
    model_columns = [
        'ë¹„ìš©', 'CPC', 'CTR', 'ROAS_3d_trend',
        'trend_score',
        'channel_naver', 'channel_meta', 'channel_google', 'channel_karrot'
    ]

    processed_data = []

    for item in features_list:
        cost = item.get('ë¹„ìš©', 100000)
        current_roas = item.get('ROAS', 200)

        # Reactì—ì„œ ë³´ë‚´ì¤€ 'trend_score' ë°›ê¸° (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 50)
        trend_score = item.get('trend_score', 50)

        # ë³´ì¡° ì§€í‘œ ì¶”ì • (â€» MVP ë‹¨ê³„ì—ì„œëŠ” ìœ ì§€, ì¶”í›„ DB ê³„ì‚°ê°’ìœ¼ë¡œ êµì²´ ê¶Œì¥)
        ctr = 1.5 + (float(current_roas) / 1000.0)
        cpc = 500
        roas_3d = float(current_roas) * 1.02

        # âœ… ì±„ë„ ì…ë ¥ì„ ìœ ì—°í•˜ê²Œ ë°›ê¸°:
        # 1) ê¸°ì¡´: ì±„ë„ëª…_Naver/Meta/Google/Karrot
        # 2) ì‹ ê·œ: channel_naver/meta/google/karrot
        channel_naver = item.get('channel_naver', item.get('ì±„ë„ëª…_Naver', 0))
        channel_meta = item.get('channel_meta', item.get('ì±„ë„ëª…_Meta', 0))
        channel_google = item.get('channel_google', item.get('ì±„ë„ëª…_Google', 0))
        channel_karrot = item.get('channel_karrot', item.get('ì±„ë„ëª…_Karrot', 0))

        row = {
            'ë¹„ìš©': float(cost),
            'CPC': float(cpc),
            'CTR': float(ctr),
            'ROAS_3d_trend': float(roas_3d),
            'trend_score': float(trend_score),

            'channel_naver': int(channel_naver),
            'channel_meta': int(channel_meta),
            'channel_google': int(channel_google),
            'channel_karrot': int(channel_karrot),
        }
        processed_data.append(row)

    df = pd.DataFrame(processed_data)

    # ë§Œì•½ ë°ì´í„°ê°€ ë¹„ì–´ìˆë‹¤ë©´ ì—ëŸ¬ ì²˜ë¦¬
    if df.empty:
        log(json.dumps({"error": "ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}, ensure_ascii=False))
        sys.exit(1)

    # ì»¬ëŸ¼ ìˆœì„œ ê°•ì œ ë§ì¶¤ (í•™ìŠµë•Œì™€ ë™ì¼í•˜ê²Œ)
    try:
        X = df[model_columns]
    except Exception as e:
        log(json.dumps({
            "error": f"ì…ë ¥ ì»¬ëŸ¼ì´ ëª¨ë¸ê³¼ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤: {str(e)}",
            "expected_columns": model_columns,
            "received_columns": list(df.columns)
        }, ensure_ascii=False))
        sys.exit(1)

    # [AI ëª¨ë¸ ë¡œë“œ ë° ì˜ˆì¸¡]
    try:
        model = xgb.XGBRegressor()
        script_dir = os.path.dirname(os.path.abspath(__file__))
        model_path = os.path.join(script_dir, 'optimal_budget_xgb_model.json')

        model.load_model(model_path)
        predicted_roas = model.predict(X)

        # âœ… ì˜ˆì¸¡ê°’ í´ë¦¬í•‘: ë¹„í˜„ì‹¤ íŠ ë°©ì§€
        CLIP_MIN = 50.0
        CLIP_MAX = 800.0
        predicted_roas = clip_predicted_roas(predicted_roas, min_roas=CLIP_MIN, max_roas=CLIP_MAX)

    except Exception as e:
        log(json.dumps({"error": f"ëª¨ë¸ ë¡œë“œ/ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}"}, ensure_ascii=False))
        sys.exit(1)

    # [ì„ í˜• ê³„íšë²• - ì˜ˆì‚° ìµœì í™”]
    try:
        n = len(predicted_roas)

        c = [-float(r) for r in predicted_roas]
        A_eq = [[1] * n]
        b_eq = [float(total_budget)]

        # âœ… ì´ì˜ˆì‚°ì— ë”°ë¼ infeasible ë°©ì§€ìš© bounds ìë™ ìƒì„±
        MIN_BUDGET_DEFAULT = 30000
        MAX_RATIO_DEFAULT = 0.6
        bounds = build_safe_bounds(
            n,
            total_budget,
            min_budget_default=MIN_BUDGET_DEFAULT,
            max_ratio_default=MAX_RATIO_DEFAULT
        )

        result = linprog(c, A_eq=A_eq, b_eq=b_eq, bounds=bounds, method='highs')

        if result.success:
            allocated_budget = result.x

            real_expected_revenue = np.sum(allocated_budget * (predicted_roas / 100.0))

            # âœ… [PRO] ì»¨ì„¤íŒ… ë¦¬í¬íŠ¸ ìƒì„±
            report_text = build_pro_report(
                total_budget=total_budget,
                allocated_budget=allocated_budget,
                predicted_roas=predicted_roas,
                expected_revenue=real_expected_revenue,
                duration=duration,
                clip_min=CLIP_MIN,
                clip_max=CLIP_MAX,
                min_budget_default=MIN_BUDGET_DEFAULT,
                max_ratio_default=MAX_RATIO_DEFAULT
            )

            # duration ì ìš© íˆìŠ¤í† ë¦¬ ìƒì„±
            history_data = generate_past_history(predicted_roas, duration=duration)

            output = {
                "status": "success",
                "total_budget": int(total_budget),
                "allocated_budget": [int(b) for b in np.round(allocated_budget, 0)],
                "predicted_roas": [round(float(r), 2) for r in predicted_roas],
                "expected_revenue": int(round(real_expected_revenue, 0)),
                "history": history_data,
                "ai_report": report_text
            }
        else:
            output = {"status": "failed", "reason": "ìµœì í™” ì‹¤íŒ¨", "detail": str(result.message)}

    except Exception as e:
        log(json.dumps({"error": f"ìµœì í™” ê³„ì‚° ì‹¤íŒ¨: {str(e)}"}, ensure_ascii=False))
        sys.exit(1)

    # âœ… stdoutì—ëŠ” JSONë§Œ 1ë²ˆ ì¶œë ¥ (Node íŒŒì‹± ì•ˆì •)
    sys.stdout.write(json.dumps(output, cls=NumpyEncoder, ensure_ascii=False))
    sys.stdout.flush()

if __name__ == "__main__":
    main()